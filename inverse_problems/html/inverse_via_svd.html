
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>inverse_via_svd</title><meta name="generator" content="MATLAB 9.11"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2022-03-06"><meta name="DC.source" content="inverse_via_svd.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
span.typesection { color:#A0522D }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><pre class="codeinput">clear <span class="string">all</span>;
close <span class="string">all</span>;
</pre><p>Let g : [0,1] &#8594; R be a differentiable function satisfying g(0) = 0. We assume to know the (noisy) values of g at the points tj = j/100, j = 1,2,..,100. The goal is to estimate the derivative of g at these same points and at the origin. This problem can be tackled by transforming it into a matrix equation: If we denote f = g&#8242;, then g(t) = \int_0_to_t f(s)ds, t &#8712; [0,1]. The measurement y = (y1, y2, . . . , y100)^T &#8712; R^100 is therefore y_j = g(t_j) + n_j, where nj is the measurement error. The point values x = (f(t0),f(t1),...,f(t100))^T &#8712; R^^101 are the unknowns.</p><pre class="codeinput">N = 100;
T = 1;
</pre><p>(a) Write the forward problem in the form y =  Ax + n via discretization. Create the system matrix A &#8712; R^100&times;101 by using the trapezoidal rule</p><pre class="codeinput">A = tril(ones(N + 1)) - 1/2 * eye(N + 1);
A(1,:) = [];
A(:, 1) = 1/2;
A = 1/N * A;
</pre><p>(b) Characterize Ker(A) and Ran(A)^&#8869;.</p><p>(c) Use Matlab to compute the singular value decomposition and the Moore&#8211;Penrose pseudoinverse of A. Plot the singular values of A.</p><pre class="codeinput"><span class="comment">% svd</span>
[U L V] = svd(A);

<span class="comment">% Pseudo-inverse</span>
A_pinv = pinv(A);

<span class="comment">% plot of singular values</span>
figure(1);
semilogy(diag(L), <span class="string">'+'</span>, <span class="string">'LineWidth'</span>, 2);
title(<span class="string">'Singular values of discretization matrix'</span>);
xlabel(<span class="string">'indexes'</span>);
ylabel(<span class="string">'singular values'</span>);
grid <span class="string">on</span>
</pre><img vspace="5" hspace="5" src="inverse_via_svd_01.png" alt=""> <p>(d) Consider the linear system (1) when g(t) = 2 cos(&#960;t) sin^2(4&#960;t) &#8722; 10t^2 i.e., form y by evaluating this function at the grid points and adding some measurement noise. Compute the minimum norm solution A^&#8224;*y with no noise and when each nj is an independent realization of a normally distributed random variable with zero mean and standard deviation 0.1. Plot the obtained approximations and compare them with the exact derivative. Does the use of the pseudoinverse give reasonable results in both cases?</p><pre class="codeinput">t = linspace(1/N, 1, N);
g = (2 * cos(pi*t) .* sin(4*pi*t).^2 - 10 * t.^2)';
f = -2 * pi * sin(pi*t) .* sin(4*pi*t).^2 + 16 * pi * sin(4*pi*t) .* cos(4*pi*t) .* cos(pi*t) - 20*t;

<span class="comment">% Solution with no noise:</span>
y = A_pinv * g;

<span class="comment">% plot solution without noise</span>
figure(2);
hold <span class="string">on</span>
plot([0, t], y, <span class="string">'LineWidth'</span>, 1);
plot(t, f, <span class="string">'LineWidth'</span>, 1);
title(<span class="string">'Reconstruction with no noise'</span>);
legend(<span class="string">'Approximation'</span>, <span class="string">'Analytical'</span>);
xlabel(<span class="string">'t_i'</span>);
ylabel(<span class="string">'f(t_i)'</span>);
grid <span class="string">on</span>
hold <span class="string">off</span>

<span class="comment">% Solution with Gaussian noise:</span>
s = 0.1;
noise = s * randn(N, 1);
g_n = g + noise;
y_n = A_pinv * g_n;

<span class="comment">% plot solution with Gaussian noise</span>
figure(3);
hold <span class="string">on</span>
plot([0, t], y_n, <span class="string">'LineWidth'</span>, 1);
plot(t, f, <span class="string">'LineWidth'</span>, 1);
title(<span class="string">'Reconstruction with Gaussian noise'</span>);
legend(<span class="string">'Approximation'</span>, <span class="string">'Analytical'</span>);
xlabel(<span class="string">'t_i'</span>);
ylabel(<span class="string">'f(t_i)'</span>);
grid <span class="string">on</span>
hold <span class="string">off</span>

<span class="comment">% we observe that solutions without Gaussian noise is almost perfect</span>
<span class="comment">% approximation of the analytical derivative, while solution with gaussian</span>
<span class="comment">% noise is very distored. Clearly, the second solution is not really</span>
<span class="comment">% reasonable, while the first one might be just too good.</span>
</pre><img vspace="5" hspace="5" src="inverse_via_svd_02.png" alt=""> <img vspace="5" hspace="5" src="inverse_via_svd_03.png" alt=""> <p>(e) Try an alternative approach and approximately solve (1) in the noisy case by resorting to singular value truncation (the truncated SVD solution). Produce three reconstructions: When &#8216;inverting&#8217; A, take into account the singular values that are larger than (i) 0.002, (ii) 0.02 and (iii) 0.2, respectively. Plot the obtained approximations and compare them with the exact derivative. Which of the three spectral cut-offs gives the best reconstruction?</p><pre class="codeinput">lambdas = [0.002, 0.02, 0.2];
diagonal = diag(L);

<span class="keyword">for</span> l = 1:3
    <span class="comment">% compute truncated svd</span>
    n = max(find(diagonal &gt; lambdas(l)));
    sv = [1./diagonal(1:n); zeros(N-n, 1)];
    A_pinv_n = V * [diag(sv); zeros(1, N)] * U';

    <span class="comment">% solve inverse problem</span>
    yn_t = A_pinv_n * g_n;

    <span class="comment">% plot the solution</span>
    figure(3 + l);
    hold <span class="string">on</span>
    plot([0, t], yn_t, <span class="string">'LineWidth'</span>, 1);
    plot(t, f, <span class="string">'LineWidth'</span>, 1);
    title(<span class="string">'Reconstruction with Gaussian noise and lambda'</span>, lambdas(l));
    legend(<span class="string">'Approximation'</span>, <span class="string">'Analytical'</span>);
    xlabel(<span class="string">'t_i'</span>);
    ylabel(<span class="string">'f(t_i)'</span>);
<span class="keyword">end</span>
hold <span class="string">off</span>

<span class="comment">% from the plots it is clear that solution with lambda = 0.02 gives the</span>
<span class="comment">% best reconstruction.</span>
</pre><img vspace="5" hspace="5" src="inverse_via_svd_04.png" alt=""> <img vspace="5" hspace="5" src="inverse_via_svd_05.png" alt=""> <img vspace="5" hspace="5" src="inverse_via_svd_06.png" alt=""> <p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2021b</a><br></p></div><!--
##### SOURCE BEGIN #####
clear all;
close all;
%%
% Let g : [0,1] → R be a differentiable function satisfying g(0) = 0. 
% We assume to know the (noisy) values of g at the points tj = j/100, j = 1,2,..,100. 
% The goal is to estimate the derivative of g at these same points and at the origin.
% This problem can be tackled by transforming it into a matrix equation: 
% If we denote f = g′, then g(t) = \int_0_to_t f(s)ds, t ∈ [0,1].
% The measurement y = (y1, y2, . . . , y100)^T ∈ R^100 is therefore 
% y_j = g(t_j) + n_j, where nj is the measurement error. 
% The point values x = (f(t0),f(t1),...,f(t100))^T ∈ R^^101 are the unknowns.
N = 100;
T = 1;
%%
% (a) 
% Write the forward problem in the form y =  Ax + n via discretization.
% Create the system matrix A ∈ R^100×101 by using the trapezoidal rule
A = tril(ones(N + 1)) - 1/2 * eye(N + 1);
A(1,:) = [];
A(:, 1) = 1/2;
A = 1/N * A;
%%
% (b) 
% Characterize Ker(A) and Ran(A)^⊥.
%%
% (c) 
% Use Matlab to compute the singular value decomposition and 
% the Moore–Penrose pseudoinverse of A. Plot the singular values of A.

% svd
[U L V] = svd(A);

% Pseudo-inverse
A_pinv = pinv(A);

% plot of singular values
figure(1);
semilogy(diag(L), '+', 'LineWidth', 2);
title('Singular values of discretization matrix');
xlabel('indexes');
ylabel('singular values');
grid on
%%
% (d)
% Consider the linear system (1) when 
% g(t) = 2 cos(πt) sin^2(4πt) − 10t^2
% i.e., form y by evaluating this function at the grid points and adding 
% some measurement noise.
% Compute the minimum norm solution A^†*y with no noise and when each nj is 
% an independent realization of a normally distributed random variable with
% zero mean and standard deviation 0.1. 
% Plot the obtained approximations and compare them with the exact derivative. 
% Does the use of the pseudoinverse give reasonable results in both cases?
t = linspace(1/N, 1, N);
g = (2 * cos(pi*t) .* sin(4*pi*t).^2 - 10 * t.^2)';
f = -2 * pi * sin(pi*t) .* sin(4*pi*t).^2 + 16 * pi * sin(4*pi*t) .* cos(4*pi*t) .* cos(pi*t) - 20*t;

% Solution with no noise: 
y = A_pinv * g;

% plot solution without noise
figure(2);
hold on
plot([0, t], y, 'LineWidth', 1);
plot(t, f, 'LineWidth', 1);
title('Reconstruction with no noise');
legend('Approximation', 'Analytical');
xlabel('t_i');
ylabel('f(t_i)');
grid on
hold off

% Solution with Gaussian noise:
s = 0.1;
noise = s * randn(N, 1);
g_n = g + noise;
y_n = A_pinv * g_n;

% plot solution with Gaussian noise
figure(3);
hold on
plot([0, t], y_n, 'LineWidth', 1);
plot(t, f, 'LineWidth', 1);
title('Reconstruction with Gaussian noise');
legend('Approximation', 'Analytical');
xlabel('t_i');
ylabel('f(t_i)');
grid on
hold off

% we observe that solutions without Gaussian noise is almost perfect
% approximation of the analytical derivative, while solution with gaussian
% noise is very distored. Clearly, the second solution is not really
% reasonable, while the first one might be just too good.
%%
% (e)
% Try an alternative approach and approximately solve (1) in the noisy case
% by resorting to singular value truncation (the truncated SVD solution). 
% Produce three reconstructions: When ‘inverting’ A, take into account the 
% singular values that are larger than (i) 0.002, (ii) 0.02 and (iii) 0.2, 
% respectively. Plot the obtained approximations and compare them with the
% exact derivative. 
% Which of the three spectral cut-offs gives the best reconstruction?

lambdas = [0.002, 0.02, 0.2];
diagonal = diag(L);

for l = 1:3
    % compute truncated svd
    n = max(find(diagonal > lambdas(l)));
    sv = [1./diagonal(1:n); zeros(N-n, 1)];
    A_pinv_n = V * [diag(sv); zeros(1, N)] * U';

    % solve inverse problem
    yn_t = A_pinv_n * g_n;

    % plot the solution
    figure(3 + l);
    hold on
    plot([0, t], yn_t, 'LineWidth', 1);
    plot(t, f, 'LineWidth', 1);
    title('Reconstruction with Gaussian noise and lambda', lambdas(l));
    legend('Approximation', 'Analytical');
    xlabel('t_i');
    ylabel('f(t_i)');
end
hold off

% from the plots it is clear that solution with lambda = 0.02 gives the 
% best reconstruction.
##### SOURCE END #####
--></body></html>